# üß† Data Pipeline SDLC Emulator

Una aplicaci√≥n web que emula el ciclo de vida completo de desarrollo de pipelines de datos (Data Pipeline SDLC), desde la ideaci√≥n hasta el despliegue. Utiliza agentes inteligentes para automatizar tareas clave, generar documentaci√≥n, producir datos sint√©ticos, y validar la calidad de los datos en cada etapa.

---

## üöÄ ¬øQu√© hace esta plataforma?

Esta aplicaci√≥n gu√≠a y automatiza el flujo completo de construcci√≥n de un pipeline de datos moderno, siguiendo buenas pr√°cticas de ingenier√≠a y anal√≠tica:

1. **Historias de usuario ‚Üí ARD + Jira**
   - Transforma historias de usuario en requerimientos anal√≠ticos (ARD) validados y publicados en Confluence.
   - Crea autom√°ticamente las tareas t√©cnicas en Jira.

2. **Dise√±o de recolecci√≥n de datos**
   - Genera autom√°ticamente especificaciones de eventos (Tagging Spec) incluyendo nombres, condiciones de activaci√≥n y par√°metros.
   - Crea un plan de tracking versionado, alineado con el ARD, para fuentes digitales o sistemas legacy.

3. **Desarrollo inicial con copiloto**
   - Genera scripts SQL que implementan la l√≥gica de negocio sobre Snowflake.
   - Produce el documento `snowformation`, el contrato de datos del framework IRIS.

4. **Generaci√≥n de datos sint√©ticos**
   - Simula datasets para cada fase del pipeline (tracking, Google Analytics, S3, dominio, etc.).
   - Permite validar los flujos desde etapas tempranas.

5. **Pruebas automatizadas del pipeline**
   - Ejecuta validaciones autom√°ticas de datos.
   - Eval√∫a m√©tricas de calidad en 6 dimensiones clave: *completitud, exactitud, validez, unicidad, integridad, puntualidad*.

6. **Documentaci√≥n de evidencias**
   - Genera documentaci√≥n y evidencia para soportar la puesta en producci√≥n del modelo o flujo de datos.
   - Integra con entornos de despliegue y asegura la trazabilidad.

---

## üß© Arquitectura Modular

- **Frontend:** Interfaz web para navegar cada fase del SDLC.
- **Backend:** Orquestador de agentes y generaci√≥n de artefactos.
- **Integraciones:** APIs para Confluence, Jira, Google Analytics, Snowflake, etc.
- **Almacenamiento:** Base de datos para configuraci√≥n y estado de ejecuci√≥n.

---

## ü§ñ Agentes Inteligentes

- **Story-to-ARD Agent:** Traduce requerimientos en documentos anal√≠ticos.
- **TrackingSpec Agent:** Crea y valida convenciones de eventos y metadatos.
- **Pipeline Generator Agent:** Produce SQL y contratos de datos (`snowformation`).
- **Synthetic Data Agent:** Genera datasets falsos para pruebas unitarias y QA.
- **QA Agent:** Ejecuta pruebas y validaciones automatizadas.
- **Deployment Evidence Agent:** Documenta resultados y flujos de aprobaci√≥n.

---

## üõ†Ô∏è Instalaci√≥n (pr√≥ximamente)

```bash
# Clonar el repositorio
git clone https://github.com/christianivh/ai-data-pipeline.git
cd ai-data-pipeline

# Instalar dependencias (por definir: Node, Python, etc.)
npm install
# o
pip install -r requirements.txt

# Iniciar entorno local
npm run dev
# o
streamlit run app.py
